{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sentiment_Analysis_with_BiLSTM_Attention.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 748
        },
        "id": "Np5_jSqqdMkj",
        "outputId": "8ea7ed42-50f3-4ba0-89a4-dcb3a628b09d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==1.8.0+cu111\n",
            "  Downloading https://download.pytorch.org/whl/cu111/torch-1.8.0%2Bcu111-cp37-cp37m-linux_x86_64.whl (1982.2 MB)\n",
            "\u001b[K     |█████████████▌                  | 834.1 MB 1.5 MB/s eta 0:13:11tcmalloc: large alloc 1147494400 bytes == 0x3a834000 @  0x7f296a581615 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x548ae9 0x51566f 0x549576 0x593fce 0x548ae9 0x5127f1 0x598e3b 0x511f68 0x598e3b 0x511f68 0x598e3b 0x511f68 0x4bc98a 0x532e76 0x594b72 0x515600 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x5118f8 0x593dd7\n",
            "\u001b[K     |█████████████████               | 1055.7 MB 1.2 MB/s eta 0:12:24tcmalloc: large alloc 1434370048 bytes == 0x7ee8a000 @  0x7f296a581615 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x548ae9 0x51566f 0x549576 0x593fce 0x548ae9 0x5127f1 0x598e3b 0x511f68 0x598e3b 0x511f68 0x598e3b 0x511f68 0x4bc98a 0x532e76 0x594b72 0x515600 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x5118f8 0x593dd7\n",
            "\u001b[K     |█████████████████████▋          | 1336.2 MB 1.2 MB/s eta 0:08:56tcmalloc: large alloc 1792966656 bytes == 0x3cbc000 @  0x7f296a581615 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x548ae9 0x51566f 0x549576 0x593fce 0x548ae9 0x5127f1 0x598e3b 0x511f68 0x598e3b 0x511f68 0x598e3b 0x511f68 0x4bc98a 0x532e76 0x594b72 0x515600 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x5118f8 0x593dd7\n",
            "\u001b[K     |███████████████████████████▎    | 1691.1 MB 1.2 MB/s eta 0:04:03tcmalloc: large alloc 2241208320 bytes == 0x6eaa4000 @  0x7f296a581615 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x548ae9 0x51566f 0x549576 0x593fce 0x548ae9 0x5127f1 0x598e3b 0x511f68 0x598e3b 0x511f68 0x598e3b 0x511f68 0x4bc98a 0x532e76 0x594b72 0x515600 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x5118f8 0x593dd7\n",
            "\u001b[K     |████████████████████████████████| 1982.2 MB 1.2 MB/s eta 0:00:01tcmalloc: large alloc 1982251008 bytes == 0xf4406000 @  0x7f296a5801e7 0x4a3940 0x4a39cc 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x593dd7 0x511e2c 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x548ae9\n",
            "tcmalloc: large alloc 2477817856 bytes == 0x16a672000 @  0x7f296a581615 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x593dd7 0x511e2c 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576\n",
            "\u001b[K     |████████████████████████████████| 1982.2 MB 5.3 kB/s \n",
            "\u001b[?25hCollecting torchvision==0.9.0+cu111\n",
            "  Downloading https://download.pytorch.org/whl/cu111/torchvision-0.9.0%2Bcu111-cp37-cp37m-linux_x86_64.whl (17.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 17.6 MB 33 kB/s \n",
            "\u001b[?25hCollecting torchaudio==0.8.0\n",
            "  Downloading torchaudio-0.8.0-cp37-cp37m-manylinux1_x86_64.whl (1.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.9 MB 4.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.8.0+cu111) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.8.0+cu111) (4.2.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.9.0+cu111) (7.1.2)\n",
            "Installing collected packages: torch, torchvision, torchaudio\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.11.0+cu113\n",
            "    Uninstalling torch-1.11.0+cu113:\n",
            "      Successfully uninstalled torch-1.11.0+cu113\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.12.0+cu113\n",
            "    Uninstalling torchvision-0.12.0+cu113:\n",
            "      Successfully uninstalled torchvision-0.12.0+cu113\n",
            "  Attempting uninstall: torchaudio\n",
            "    Found existing installation: torchaudio 0.11.0+cu113\n",
            "    Uninstalling torchaudio-0.11.0+cu113:\n",
            "      Successfully uninstalled torchaudio-0.11.0+cu113\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtext 0.12.0 requires torch==1.11.0, but you have torch 1.8.0+cu111 which is incompatible.\u001b[0m\n",
            "Successfully installed torch-1.8.0+cu111 torchaudio-0.8.0 torchvision-0.9.0+cu111\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "torch"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install torch==1.8.0+cu111 torchvision==0.9.0+cu111 torchaudio==0.8.0 -f https://download.pytorch.org/whl/torch_stable.html"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchtext==0.9"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        },
        "id": "_zeD3IRqj6UI",
        "outputId": "923a22e4-b454-47a1-8311-60ebd304e9af"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchtext==0.9\n",
            "  Downloading torchtext-0.9.0-cp37-cp37m-manylinux1_x86_64.whl (7.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.1 MB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch==1.8.0 in /usr/local/lib/python3.7/dist-packages (from torchtext==0.9) (1.8.0+cu111)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext==0.9) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchtext==0.9) (1.21.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext==0.9) (4.64.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.8.0->torchtext==0.9) (4.2.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.9) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.9) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.9) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.9) (2022.5.18.1)\n",
            "Installing collected packages: torchtext\n",
            "  Attempting uninstall: torchtext\n",
            "    Found existing installation: torchtext 0.12.0\n",
            "    Uninstalling torchtext-0.12.0:\n",
            "      Successfully uninstalled torchtext-0.12.0\n",
            "Successfully installed torchtext-0.9.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "torchtext"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import torch\n",
        "import random\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torchtext.legacy import data, datasets\n",
        "from tqdm import tqdm\n",
        "\n",
        "SEED = 42\n",
        "\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "metadata": {
        "id": "5gmilCmMkMr7"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fqpVkY-D1zLd",
        "outputId": "17c7986f-bd59-4a9c-f4f7-32907b9a59ec"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Jun 13 20:52:54 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   62C    P8    10W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TEXT = data.Field(tokenize = 'spacy', include_lengths = True)\n",
        "LABEL = data.LabelField(dtype = torch.float)"
      ],
      "metadata": {
        "id": "BHROOByUkPIf"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, test_data = datasets.IMDB.splits(TEXT, LABEL)"
      ],
      "metadata": {
        "id": "fvN-o_UbkuNJ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, valid_data = train_data.split(random_state = random.seed(SEED))"
      ],
      "metadata": {
        "id": "jvTUymDpkxIC"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_VOCAB_SIZE = 25_000\n",
        "\n",
        "TEXT.build_vocab(train_data, \n",
        "                 max_size = MAX_VOCAB_SIZE)\n",
        "\n",
        "LABEL.build_vocab(train_data)"
      ],
      "metadata": {
        "id": "bKG_JLrqkysf"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 64\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
        "    (train_data, valid_data, test_data), \n",
        "    batch_size = BATCH_SIZE,\n",
        "    sort_within_batch = True,\n",
        "    device = device)"
      ],
      "metadata": {
        "id": "iGlkUL96k7nX"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTMAttention(nn.Module):\n",
        "    def __init__(self, input_dim, emb_dim, hidden_dim, output_dim, n_layers, \n",
        "                 dropout, pad_idx):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
        "        self.n_layers = n_layers\n",
        "        self.pad_idx = pad_idx\n",
        "        self.rnn = nn.LSTM(emb_dim, hidden_dim, num_layers=n_layers, bidirectional=True,\n",
        "                           dropout=dropout)\n",
        "        self.fc = nn.Linear(hidden_dim*2, output_dim)\n",
        "        self.attn = nn.Linear(hidden_dim*4, hidden_dim*2)\n",
        "        self.v = nn.Linear(hidden_dim*2, 1, bias=False)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def create_mask(self, src):\n",
        "        # src: [src_len, batch_size]\n",
        "        mask = (src != self.pad_idx)\n",
        "        mask = mask.permute(1, 0)\n",
        "        \n",
        "        # mask: [batch_size, src_len]\n",
        "        return mask\n",
        "\n",
        "    def attention(self, hidden, outputs, mask):\n",
        "        # hidden: [batch_size, hidden_dim * 2]\n",
        "        # outputs: [seq_len, batch_size, hidden_dim * 2]\n",
        "        # mask: [batch_size, src_len]\n",
        "\n",
        "        batch_size = outputs.shape[1]\n",
        "        seq_len = outputs.shape[0]\n",
        "\n",
        "        # hidden: [batch_size, seq_len, hidden_dim * 2]\n",
        "        hidden = hidden.unsqueeze(1).repeat(1, seq_len, 1)\n",
        "        \n",
        "        # outputs: [batch_size, seq_len, hidden_dim * 2]\n",
        "        outputs = outputs.permute(1, 0, 2)\n",
        "\n",
        "        # energy: [batch_size, seq_len, hidden_dim * 2]\n",
        "        energy = torch.tanh(self.attn(torch.cat((hidden, outputs), dim=2)))\n",
        "        attention_energy = self.v(energy).squeeze(2)\n",
        "\n",
        "        # attention_energy: [batch_size, seq_len]\n",
        "        attention_energy = attention_energy.masked_fill(mask == 0, -1e10)\n",
        "\n",
        "        return F.softmax(attention_energy, dim=1)\n",
        "\n",
        "    def forward(self, src, src_lengths):\n",
        "        batch_size = src.shape[1]\n",
        "        mask = self.create_mask(src)\n",
        "\n",
        "        embedded = self.dropout(self.embedding(src))\n",
        "\n",
        "        packed_input = nn.utils.rnn.pack_padded_sequence(embedded, src_lengths)\n",
        "        packed_outputs, (hidden, _) = self.rnn(packed_input)\n",
        "        outputs, _ = nn.utils.rnn.pad_packed_sequence(packed_outputs)\n",
        "\n",
        "        # outputs: [seq_len, batch_size, hid_dim * 2]\n",
        "        # hidden: [num_layers * num_directions, batch_size, hidden_dim]\n",
        "\n",
        "        hidden = hidden.view(self.n_layers, 2, batch_size, -1)\n",
        "\n",
        "        # concat final forward and backward hidden states\n",
        "        hidden = torch.cat((hidden[-1][0][:], hidden[-1][1][:]), dim=1)\n",
        "        hidden = self.dropout(hidden)\n",
        "\n",
        "        attention_energies = self.attention(hidden, outputs, mask)\n",
        "\n",
        "        attention_energies = attention_energies.unsqueeze(1)\n",
        "\n",
        "        outputs = outputs.permute(1, 0, 2)\n",
        "\n",
        "        # attention_energies: [batch_size, 1, seq_len]\n",
        "        # outputs: [batch_size, seq_len, hidden_dim * 2]\n",
        "\n",
        "        # weighted: [batch_size, 1, hidden_dim * 2]\n",
        "        weighted = torch.bmm(attention_energies, outputs)\n",
        "\n",
        "        # weighted: [batch_size, hidden_dim * 2]\n",
        "        weighted = weighted.squeeze(1)\n",
        "\n",
        "        logits = self.fc(weighted)\n",
        "        # logits: [batch_size, output_dim]\n",
        "        return logits, attention_energies.squeeze(1)\n",
        "\n",
        "        "
      ],
      "metadata": {
        "id": "L6j37OUmk_Xi"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "INPUT_DIM = len(TEXT.vocab)\n",
        "EMBEDDING_DIM = 100\n",
        "HIDDEN_DIM = 256\n",
        "OUTPUT_DIM = 1\n",
        "N_LAYERS = 2\n",
        "DROPOUT = 0.5\n",
        "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
        "\n",
        "model = LSTMAttention(INPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM, N_LAYERS, DROPOUT, PAD_IDX).to(device)"
      ],
      "metadata": {
        "id": "2EDQeo2Av5zI"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nQava2QawHTq",
        "outputId": "c18b49b2-53f3-4ade-8f76-b27709cd8abf"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LSTMAttention(\n",
            "  (embedding): Embedding(25002, 100)\n",
            "  (rnn): LSTM(100, 256, num_layers=2, dropout=0.5, bidirectional=True)\n",
            "  (fc): Linear(in_features=512, out_features=1, bias=True)\n",
            "  (attn): Linear(in_features=1024, out_features=512, bias=True)\n",
            "  (v): Linear(in_features=512, out_features=1, bias=False)\n",
            "  (dropout): Dropout(p=0.5, inplace=False)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.Adam(model.parameters())\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "metadata": {
        "id": "0GA2vXYQwLJS"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def binary_accuracy(preds, y):\n",
        "    predicted = torch.round(torch.sigmoid(preds))\n",
        "    correct = (predicted == y).float()\n",
        "    acc = correct.sum() / len(correct)\n",
        "    return acc"
      ],
      "metadata": {
        "id": "VBRJaXpEwQ6z"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "\n",
        "    model.train()\n",
        "    \n",
        "    for batch in iterator:\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        input, input_lengths = batch.text\n",
        "        preds, _ = model(input, input_lengths.to('cpu'))\n",
        "        preds = preds.squeeze(1)\n",
        "\n",
        "\n",
        "        loss = criterion(preds, batch.label)\n",
        "        acc = binary_accuracy(preds, batch.label)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "metadata": {
        "id": "H_IjfucWxO-i"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "\n",
        "    model.eval()\n",
        "    \n",
        "    for batch in iterator:\n",
        "        input, input_lengths = batch.text\n",
        "        preds, _ = model(input, input_lengths.to('cpu'))\n",
        "        preds = preds.squeeze(1)   \n",
        "        loss = criterion(preds, batch.label)\n",
        "        acc = binary_accuracy(preds, batch.label)\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "metadata": {
        "id": "jtwygUosxXyp"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "metadata": {
        "id": "qdivW7pvxaSC"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "N_EPOCHS = 5\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "    start_time = time.time()\n",
        "    # torch.cuda.empty_cache()\n",
        "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
        "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
        "\n",
        "    end_time = time.time()\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'lstm-attention.pt')\n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')\n",
        "\n",
        "model.load_state_dict(torch.load('lstm-attention.pt'))\n",
        "\n",
        "test_loss, test_acc = evaluate(model, test_iterator, criterion)\n",
        "\n",
        "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yIidsv_excLa",
        "outputId": "7247c9bd-414f-4232-d161-db2d58573054"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 01 | Epoch Time: 0m 47s\n",
            "\tTrain Loss: 0.432 | Train Acc: 80.41%\n",
            "\t Val. Loss: 0.397 |  Val. Acc: 83.21%\n",
            "Epoch: 02 | Epoch Time: 0m 49s\n",
            "\tTrain Loss: 0.353 | Train Acc: 84.86%\n",
            "\t Val. Loss: 0.329 |  Val. Acc: 85.72%\n",
            "Epoch: 03 | Epoch Time: 0m 48s\n",
            "\tTrain Loss: 0.305 | Train Acc: 87.40%\n",
            "\t Val. Loss: 0.281 |  Val. Acc: 88.84%\n",
            "Epoch: 04 | Epoch Time: 0m 49s\n",
            "\tTrain Loss: 0.261 | Train Acc: 89.54%\n",
            "\t Val. Loss: 0.289 |  Val. Acc: 89.21%\n",
            "Epoch: 05 | Epoch Time: 0m 48s\n",
            "\tTrain Loss: 0.242 | Train Acc: 90.54%\n",
            "\t Val. Loss: 0.265 |  Val. Acc: 89.86%\n",
            "Test Loss: 0.285 | Test Acc: 88.75%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy"
      ],
      "metadata": {
        "id": "itQJGmfn3KAF"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load('en')\n",
        "\n",
        "def inference(model, sentence):\n",
        "    model.eval()\n",
        "    if isinstance(sentence, str):\n",
        "        tokenized = [tok.text for tok in nlp.tokenizer(sentence)]\n",
        "    else:\n",
        "        tokenized = sentence\n",
        "    indexed = [TEXT.vocab.stoi[t] for t in tokenized]\n",
        "    length = [len(indexed)]\n",
        "    tensor = torch.LongTensor(indexed).to(device)\n",
        "    tensor = tensor.unsqueeze(1)\n",
        "    length_tensor = torch.LongTensor(length).to('cpu')\n",
        "    with torch.no_grad():\n",
        "        logits, attention = model(tensor, length_tensor)\n",
        "    print(logits)\n",
        "    prediction = torch.sigmoid(logits)\n",
        "    if prediction.item() < 0.5:\n",
        "        sentiment = \"Positive\"\n",
        "    elif prediction.item() > 0.5:\n",
        "        sentiment = \"Negative\"\n",
        "    elif prediction.item() == 0.0:\n",
        "        sentiment = \"Neutral\"\n",
        "    return tokenized, sentiment, prediction.item(), attention.squeeze()"
      ],
      "metadata": {
        "id": "lS3UBS5I1bMT"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "KJjv1nZq3TcG"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def display_attention(labels, attention):\n",
        "    attention = attention.cpu().detach().numpy()\n",
        "    attention = np.around(attention, 4)\n",
        "    fig, ax = plt.subplots(figsize=(len(labels),15))\n",
        "    im = ax.imshow([attention])\n",
        "    ax.set_xticks(np.arange(len(labels)))\n",
        "    ax.set_xticklabels(labels)\n",
        "    ax.set_yticklabels(\"\")\n",
        "    # ax = sns.heatmap([attention], vmin=0, vmax=1, annot=True, xticklabels=labels, yticklabels=False)\n",
        "    for i in range(len(labels)):\n",
        "        text = ax.text(i, 0, attention[i], ha=\"center\", va=\"center\", color=\"w\")\n",
        "    plt.show()\n",
        "    plt.close()"
      ],
      "metadata": {
        "id": "HTyuezlO3VgE"
      },
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "review = \"The movie was absolutely unwatchable\""
      ],
      "metadata": {
        "id": "d5BOklg23nCD"
      },
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokens, sentiment, predicted, attention = inference(model, review)\n",
        "print(f\"Review: {review}\")\n",
        "print(f\"predicted sentiment: {sentiment} with probability score of {predicted:.3f}\")\n",
        "display_attention(tokens, attention)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "id": "i7vzUUPC4W1m",
        "outputId": "79bc6c68-b04b-4da2-c9aa-6b5779e44eb9"
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[11.9015]], device='cuda:0')\n",
            "Review: The movie was absolutely unwatchable\n",
            "predicted sentiment: Negative with probability score of 1.000\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 360x1080 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "XIHGZYKQ4ZMr"
      },
      "execution_count": 38,
      "outputs": []
    }
  ]
}